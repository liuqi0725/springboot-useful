<?xml version="1.0" encoding="UTF-8"?>
<!--日志级别以及优先级排序: OFF > FATAL > ERROR > WARN > INFO > DEBUG > TRACE > ALL -->
<!--Configuration后面的status,这个用于设置log4j2自身内部的信息输出,可以不设置,当设置成trace时,你会看到log4j2内部各种详细输出 -->
<!--monitorInterval：Log4j能够自动检测修改配置 文件和重新配置本身,设置间隔秒数 -->
<configuration status="WARN" monitorInterval="1800">
    <Properties>
        <!--
            日志默认存放的位置,这里设置为项目根路径下,也可指定绝对路径
            1. 绝对路径     比如  /User/liuqi/logs/xxx
            2. tomcat 目录    ${sys:catalina.home}
            3. web 目录       ${web:rootDir}     ${web:rootDir}是web项目根路径,java项目没有这个变量,需要删掉,否则会报异常
            4. 项目本地目录  logs 或 /logs  即当前项目根目录下 [springboot 项目建议]
        -->
        <property name="basePath">logs</property>

        <!-- 日志默认输出级别 -->
        <property name="output_log_level">INFO</property>
        <!-- 控制台显示的日志最低级别 -->
        <property name="console_print_level">INFO</property>
        <!--第三方输出级别-->
        <property name="vendor_log_level">INFO</property>

        <!--sql 日志级别-->
        <property name="sql_log_level">DEBUG</property>

        <!--flow 日志级别-->
        <property name="flow_log_level">DEBUG</property>
        <!-- Pattern 输出格式 -->
        <!--
            %d{yyyy-MM-dd HH:mm:ss, SSS} : 日志生产时间
            %t : 线程名称 链接信息
            %p : 日志级别 DEBUG、TRACE、INFO、WARN、ERROR %5p 输出 5 种
            %level : 日志级别 默认%-5level 级别的
            %c : logger的名称
            %logger : logger的名称
            %C : Java类名
            %F : 文件名
            %m : 日志内容
            %n : 换行符
            %L : 日志输出所在行数
            %M : 日志输出所在方法名
            highlight 高亮
        -->
        <!-- 控制台默认输出格式,"%-5level":日志级别,"%l":输出完整的错误位置,是小写的L,因为有行号显示,所以影响日志输出的性能 %t 输出产生该日志事件的线程名-->
        <property name="console_log_pattern">%d{yyyy-MM-dd HH:mm:ss.SSS}  %highlight{%-5level %l} - %m%n</property>
        <!-- 日志文件默认输出格式,不带行号输出(行号显示会影响日志输出性能);%C:大写,类名;%M:方法名;%m:错误信息;%n:换行 -->
        <property name="log_pattern">%d{yyyy-MM-dd HH:mm:ss.SSS} [%-5level] %C.%M - %m%n</property>
        <!-- 日志默认切割的最小单位 -->
        <property name="every_file_size">20MB</property>

        <!--
            日志文件定义
        -->

        <!-- 日志默认存放路径(所有级别日志) -->
        <property name="rolling_fileName">${basePath}/all.log</property>
        <!-- 日志默认压缩路径,将超过指定文件大小的日志,自动存入按"年月"建立的文件夹下面并进行压缩,作为存档 -->
        <property name="rolling_filePattern">${basePath}/time-based-logs/%d{yyyy-MM-dd}-all-%i.log.zip</property>
        <!-- 日志默认同类型日志,同一文件夹下可以存放的数量,不设置此属性则默认为7个 -->
        <property name="rolling_max">50</property>
        <!-- ======================================== -->

        <!-- Info日志默认存放路径(Info级别日志) -->
        <property name="info_fileName">${basePath}/info.log</property>
        <!-- Info日志默认压缩路径,将超过指定文件大小的日志,自动存入按"年月"建立的文件夹下面并进行压缩,作为存档 -->
        <property name="info_filePattern">${basePath}/time-based-logs/%d{yyyy-MM-dd}-info-%i.log.zip</property>
        <!-- Info日志默认同一文件夹下可以存放的数量,不设置此属性则默认为7个 -->
        <property name="info_max">10</property>
        <!-- ======================================== -->

        <!-- Warn日志默认存放路径(Warn级别日志) -->
        <property name="warn_fileName">${basePath}/warn.log</property>
        <!-- Warn日志默认压缩路径,将超过指定文件大小的日志,自动存入按"年月"建立的文件夹下面并进行压缩,作为存档 -->
        <property name="warn_filePattern">${basePath}/time-based-logs/%d{yyyy-MM-dd}-warn-%i.log.zip</property>
        <!-- Warn日志默认同一文件夹下可以存放的数量,不设置此属性则默认为7个 -->
        <property name="warn_max">10</property>
        <!-- ======================================== -->

        <!-- Error日志默认存放路径(Error级别日志) -->
        <property name="error_fileName">${basePath}/error.log</property>
        <!-- Error日志默认压缩路径,将超过指定文件大小的日志,自动存入按"年月"建立的文件夹下面并进行压缩,作为存档 -->
        <property name="error_filePattern">${basePath}/time-based-logs/%d{yyyy-MM-dd}-error-%i.log.zip</property>
        <!-- Error日志默认同一文件夹下可以存放的数量,不设置此属性则默认为7个 -->
        <property name="error_max">10</property>
        <!-- ======================================== -->

        <!-- druid日志默认存放路径(Error级别日志) -->
        <property name="druid_fileName">${basePath}/druid.log</property>
        <!-- druid日志默认压缩路径,将超过指定文件大小的日志,自动存入按"年月"建立的文件夹下面并进行压缩,作为存档 -->
        <property name="druid_filePattern">${basePath}/time-based-logs/%d{yyyy-MM-dd}-druid-%i.log.zip</property>
        <!-- druid日志默认同一文件夹下可以存放的数量,不设置此属性则默认为7个 -->
        <property name="druid_max">20</property>
        <!-- ======================================== -->

        <!-- fow 日志默认存放路径(All级别日志) -->
        <property name="flow_fileName">${basePath}/flow.log</property>
        <!-- druid日志默认压缩路径,将超过指定文件大小的日志,自动存入按"年月"建立的文件夹下面并进行压缩,作为存档 -->
        <property name="flow_filePattern">${basePath}/time-based-logs/%d{yyyy-MM-dd}-flow-%i.log.zip</property>
        <!-- druid日志默认同一文件夹下可以存放的数量,不设置此属性则默认为7个 -->
        <property name="flow_max">20</property>
        <!-- ======================================== -->


        <!-- 控制台显示的日志最低级别 -->
        <property name="console_print_level">DEBUG</property>

    </Properties>

    <!--定义appender -->
    <!--
        appenders 日志输出源，可以在标签内定义多个输出源
        日志级别 ALL < TRACE < DEBUG < INFO < WARN < ERROR < FATAL < OFF
    -->
    <appenders>
        <!-- 用来定义输出到控制台的配置 -->
        <Console name="Console" target="SYSTEM_OUT">
            <!-- 设置控制台只输出level及以上级别的信息(onMatch),其他的直接拒绝(onMismatch) -->
            <ThresholdFilter level="${console_print_level}" onMatch="ACCEPT" onMismatch="DENY"/>
            <!-- 设置输出格式,不设置默认为:%m%n -->
            <PatternLayout pattern="${console_log_pattern}"/>
        </Console>

        <!--
        RollingFile:
            name：表示文件Appender的名称，<logger>中会依赖此名称，起名没有具体要求，但最好简明直译；
            fileName：表示生成的日志文件名称；
            append：表示新生成的日志是否追加到日志文件中，如果为true则表示追加，false表示覆盖原有日志信息；
            immediateFlush：表示日志打印请求是否立即输出，true为立即，false表示使用缓存；
            bufferedIO：表示日志打印请求是否使用缓存，true为使用，false为不使用；
            bufferSize：表示日志打印请求的使用缓存的大小，默认为8096字节；
        -->
        <!-- 打印root中指定的level级别以上的日志到文件 -->
        <RollingFile name="RollingFile" fileName="${rolling_fileName}"
                     filePattern="${rolling_filePattern}">
            <PatternLayout pattern="${log_pattern}"/>
            <Policies>
                <!-- jvm重启就进行一次rollover-->
                <OnStartupTriggeringPolicy />
                <!-- 文件大小达到20mb进行一次rollover -->
                <SizeBasedTriggeringPolicy size="${every_file_size}" />
                <!--
                TimeBasedTriggeringPolicy
                    是最多用到的Policy,重复写文件的递归时间

                    interval 默认值是1，根据filePattern中日期的最小单位，例如在该配置里是mm（分钟），设置interval="2"则每隔两分钟将发生一次rollover，
                    按当前配置，具体表现就是隔两分钟得到一个log.zip。

                    modulate 就是让第一次rollover发生在区间边界上（即便还没到interval的时长），按照当前配置，首次rollover会发生在比如8点50分0秒，这样之后的rollover就是8点52分0秒、8点54分0秒..
                    这样做的好处在于rollover的时机就变得很有规律很好预测，生成的文件还很整齐（假设时间最小单位为天，interval="1"，那么就变成稳定每天0点自动rollover了）。
                    还有个属性叫maxRandomDelay，防止很多应用在同一时间一起rollover的，暂时不理它。
                -->
                <TimeBasedTriggeringPolicy interval="1" modulate="true" />
                <!--
                DefaultRolloverStrategy
                    默认rollover的策略
                    fileIndex有两个值，max和min，就是决定生成文件是从序号大的到序号小的，还是从序号小的到序号大。
                    min，计数器的起始值，默认是1；
                    max，计数器的最大值，默认是7。还有两个参数暂时不管。
                -->
                <DefaultRolloverStrategy max="${info_max}">
                    <Delete basePath="${basePath}/time-based-logs/" maxDepth="2">
                        <IfFileName glob="*.log.zip" />
                        <!--!Note: 这里的age必须和filePattern协调, 后者是精确到HH, 这里就要写成xH, xd就不起作用
                        另外, 数字最好 > 2, 否则可能造成删除的时候, 最近的文件还处于被占用状态,导致删除不成功!-->
                        <!--7天-->
                        <!--<IfLastModified age="168H" />-->
                        <!--1个月-->
                        <IfLastModified age="720H" />
                    </Delete>
                </DefaultRolloverStrategy>
            </Policies>

        </RollingFile>

        <!-- 打印INFO级别的日志到文件 -->
        <RollingFile name="InfoFile" fileName="${info_fileName}"
                     filePattern="${info_filePattern}">
            <PatternLayout pattern="${log_pattern}"/>

            <!-- 匹配INFO级别 -->
            <Filters>
                <ThresholdFilter level="WARN" onMatch="DENY" onMismatch="NEUTRAL"/>
                <ThresholdFilter level="INFO" onMatch="ACCEPT" onMismatch="DENY"/>
            </Filters>
            <Policies>
                <!-- jvm重启就进行一次rollover-->
                <OnStartupTriggeringPolicy />
                <!-- 文件大小达到20mb进行一次rollover -->
                <SizeBasedTriggeringPolicy size="${every_file_size}" />
                <TimeBasedTriggeringPolicy interval="1" modulate="true" />
                <DefaultRolloverStrategy max="${info_max}"/>
            </Policies>
        </RollingFile>

        <!-- 打印WARN级别的日志到文件 -->
        <RollingFile name="WarnFile" fileName="${warn_fileName}"
                     filePattern="${warn_filePattern}">
            <PatternLayout pattern="${log_pattern}"/>
            <!-- 匹配WARN级别 -->
            <Filters>
                <ThresholdFilter level="ERROR" onMatch="DENY" onMismatch="NEUTRAL"/>
                <ThresholdFilter level="WARN" onMatch="ACCEPT" onMismatch="DENY"/>
            </Filters>
            <Policies>
                <!-- jvm重启就进行一次rollover-->
                <OnStartupTriggeringPolicy />
                <!-- 文件大小达到20mb进行一次rollover -->
                <SizeBasedTriggeringPolicy size="${every_file_size}" />
                <TimeBasedTriggeringPolicy interval="1" modulate="true" />
                <DefaultRolloverStrategy max="${warn_max}"/>
            </Policies>
        </RollingFile>

        <!-- 打印ERROR级别的日志到文件 -->
        <RollingFile name="ErrorFile" fileName="${error_fileName}"
                     filePattern="${error_filePattern}">
            <PatternLayout pattern="${log_pattern}"/>
            <!-- 匹配ERROR级别 -->
            <Filters>
<!--                <ThresholdFilter level="FATAL" onMatch="DENY" onMismatch="NEUTRAL"/>-->
<!--                <ThresholdFilter level="ERROR" onMatch="ACCEPT" onMismatch="DENY"/>-->
                <!-- error 以上 都算 error -->
                <ThresholdFilter level="ERROR" />
            </Filters>
            <Policies>
                <!-- jvm重启就进行一次rollover-->
                <OnStartupTriggeringPolicy />
                <!-- 文件大小达到20mb进行一次rollover -->
                <SizeBasedTriggeringPolicy size="${every_file_size}" />
                <TimeBasedTriggeringPolicy interval="1" modulate="true" />
                <DefaultRolloverStrategy max="${error_max}"/>
            </Policies>
        </RollingFile>

        <!--druid的日志记录追加器-->
        <RollingFile name="druidSqlRollingFile" fileName="${druid_fileName}"
                     filePattern="${druid_filePattern}">
            <PatternLayout pattern="${log_pattern}"/>
            <Policies>
                <!-- jvm重启就进行一次rollover-->
                <OnStartupTriggeringPolicy />
                <!-- 文件大小达到20mb进行一次rollover -->
                <SizeBasedTriggeringPolicy size="${every_file_size}" />
                <TimeBasedTriggeringPolicy interval="1" modulate="true" />
                <DefaultRolloverStrategy max="${druid_max}"/>
            </Policies>
        </RollingFile>

    </appenders>

    <!--然后定义logger,只有定义了logger并引入的appender,appender才会生效 -->
    <loggers>

        <!--
            Logger
                name: 监听数据包名
                level: 日志级别
                additivity:
                    要看怎么设置 logger root 节点。
                    additivity = true
                        那么在 logger 下的节点 <appender-ref ref="appender" /> root 会捕获 "appender"中满足条件的日志
                    additivity = false
                        root 节点不会捕捉该日志
        -->

        <!--log4j2 自带过滤日志-->
        <Logger name="org.apache.catalina.startup.DigesterFactory" level="${vendor_log_level}" />
        <Logger name="org.apache.catalina.util.LifecycleBase" level="${vendor_log_level}" />
        <Logger name="org.apache.coyote.http11.Http11NioProtocol" level="${vendor_log_level}" />
        <logger name="org.apache.sshd.common.util.SecurityUtils" level="${vendor_log_level}"/>
        <Logger name="org.apache.tomcat.util.net.NioSelectorPool" level="${vendor_log_level}" />
        <Logger name="org.crsh.plugin" level="${vendor_log_level}" />
        <logger name="org.crsh.ssh" level="${vendor_log_level}"/>
        <Logger name="org.eclipse.jetty.util.component.AbstractLifeCycle" level="${vendor_log_level}" />
        <logger name="org.springframework.boot.actuate.autoconfigure.CrshAutoConfiguration" level="${vendor_log_level}"/>
        <logger name="org.springframework.boot.actuate.endpoint.jmx" level="${vendor_log_level}"/>
        <!--<logger name="org.thymeleaf" level="warn"/>-->
        <logger name="org.springframework.core" level="${vendor_log_level}"/>
        <logger name="org.springframework.beans" level="${vendor_log_level}"/>
        <logger name="org.springframework.context" level="${vendor_log_level}"/>
        <logger name="org.springframework.web" level="${vendor_log_level}"/>

        <!--<logger name="freemarker.cache" level="${vendor_log_level}" />-->
        <logger name="net.sf.ehcache" level="${vendor_log_level}"/>

        <!-- 记录 sql -->
        <logger name="druid.sql.Statement" level="${sql_log_level}" additivity="false">
            <appender-ref ref="druidSqlRollingFile"/>
        </logger>
        <!-- 记录 sql 结果-->
        <logger name="druid.sql.ResultSet" level="${sql_log_level}" additivity="false">
            <appender-ref ref="druidSqlRollingFile"/>
        </logger>

        <!--建立一个默认的root的logger -->
        <root level="${output_log_level}">
            <appender-ref ref="RollingFile"/>
            <appender-ref ref="Console"/>
            <appender-ref ref="InfoFile"/>
            <appender-ref ref="WarnFile"/>
            <appender-ref ref="ErrorFile"/>
        </root>
    </loggers>
</configuration>